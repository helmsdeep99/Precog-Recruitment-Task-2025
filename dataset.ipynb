{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ac0d19-7b74-484b-bf44-ee1b32574cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad769e13-5969-4d76-bdbd-b0920ece3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryLoader:\n",
    "    # Class to load and process United Nations Member States\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_url = 'https://www.un.org/en/about-us/member-states'\n",
    "\n",
    "        # Set up logger to log messages for various events and errors\n",
    "        logging.basicConfig(level=logging.INFO) # Log messages with a security level of INFO or higher\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def fetch_and_parse(self, url: str) -> BeautifulSoup:\n",
    "        # Fetch content from the URL and return parsed BeautifulSoup object\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            self.logger.error(f'Failed to fetch URL {url}: {str(e)}')\n",
    "            raise\n",
    "\n",
    "    def extract_countries(self, soup: BeautifulSoup): # -> List[str]\n",
    "        # Extract country names from parsed HTML\n",
    "        countries = []\n",
    "\n",
    "        try:\n",
    "            # 'mb-2' is a unique CSS class, not present elsewhere in the HTML\n",
    "            # This div contains the countries inside 'col-md-12' divs\n",
    "            # Names are contained in h2 elements with class 'mb-0'\n",
    "            block = soup.find('div', class_='mb-2') # Works as of 22nd January 2025\n",
    "\n",
    "            if block is None:\n",
    "                self.logger.error(f'No div with class \"mb-2\" found, URL {url} structure has likely been changed\"')\n",
    "                                            \n",
    "            for country in block.find_all('h2', class_='mb-0'): # Works as of 22nd Janaury 2025\n",
    "                name = country.text.strip()\n",
    "                if name:\n",
    "                    countries.append(name)\n",
    "\n",
    "            # Check if the countries list is populated\n",
    "            if not countries:\n",
    "                self.logger.warning('No country names found in \"mb-2\" block')\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'An error occured while extracting country names: {str(e)}')\n",
    "            raise\n",
    "\n",
    "        return countries\n",
    "\n",
    "    def clean_country_name(self, name: str) -> str:\n",
    "        # Standardizing country names for clarity and consistency, where official names are more commonly referred to by other names in international contexts.\n",
    "        name_mapping = {\n",
    "            'Democratic People\\'s Republic of Korea': 'North Korea',\n",
    "            'Democratic Republic of the Congo': 'DR Congo',\n",
    "            'Lao Peopleâ€™s Democratic Republic': 'Laos',\n",
    "            'Republic of Korea': 'South Korea',\n",
    "            'Republic of Moldova': 'Moldova',\n",
    "            'Russian Federation': 'Russia',\n",
    "            'Syrian Arab Republic': 'Syria',\n",
    "            'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n",
    "            'United Republic of Tanzania': 'Tanzania',\n",
    "        }\n",
    "\n",
    "        if name in name_mapping:\n",
    "            name = name_mapping[name] # Will change this later to generalize to lower case and other stuff\n",
    "\n",
    "        # Some country names have official designations in brackets\n",
    "        # Other country names like Venezuela have designations after a comma\n",
    "        # Remove these since they aren't relevant in the game\n",
    "\n",
    "        # Match sequence of characters in paranthesis and remove it\n",
    "        name = re.sub(r'\\([^)]*\\)', '', name)\n",
    "\n",
    "        # Remove everything after (and incluing) a comma\n",
    "        name = re.sub(r',.*', '', name)\n",
    "\n",
    "        return name\n",
    "\n",
    "    def load_countries(self): # -> List[str]\n",
    "        # Main method to load and process country data\n",
    "        try:\n",
    "            soup = self.fetch_and_parse(self.base_url)\n",
    "            countries = self.extract_countries(soup)\n",
    "            countries = [self.clean_country_name(country) for country in countries]\n",
    "\n",
    "            return countries\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Failed to load countries: {str(e)}')\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d27ee822-e7aa-4057-ae33-aa6cfe70feed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted 192 countries\n",
      "Afghanistan\n",
      "Albania\n",
      "Algeria\n",
      "Andorra\n",
      "Angola\n",
      "Antigua and Barbuda\n",
      "Argentina\n",
      "Armenia\n",
      "Australia\n",
      "Austria\n"
     ]
    }
   ],
   "source": [
    "def load_country_data(): # -> List[str]\n",
    "    # Wrapper function to create a class, load country data and return a list of countries\n",
    "    loader = CountryLoader()\n",
    "    return loader.load_countries()\n",
    "\n",
    "# Test the loader\n",
    "try:\n",
    "    countries = load_country_data()\n",
    "    print(f'Successfully extracted {len(countries)} countries')\n",
    "    print('\\n'.join(sorted(countries[:10])))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Error during testing: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fc90e5-7b3f-4d7d-a895-2a7aa7946230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityLoader:\n",
    "    # Class to load and process 500 most populated cities as per World Population Review\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_url = 'https://worldpopulationreview.com/cities'\n",
    "\n",
    "        # Set up logger to log messages for various events and errors\n",
    "        logging.basicConfig(level=logging.INFO) # Log messages with a security level of INFO or higher\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def fetch_and_parse(self, url: str) -> BeautifulSoup:\n",
    "        # Fetch content from the URL and return parsed BeautifulSoup object\n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            self.logger.error(f'Failed to fetch URL {url}: {str(e)}')\n",
    "            raise\n",
    "\n",
    "    def extract_cities(self, soup: BeautifulSoup): # -> List[str]\n",
    "        # Extract city names from parsed HTML\n",
    "        cities = []\n",
    "\n",
    "        try:\n",
    "            # 'my-6' is a unique CSS class, not present elsewhere in the HTML\n",
    "            # This div contains the names of cities inside <a class=\"text-wpr-link\">\n",
    "            block = soup.find('div', class_='my-6') # Works as of 22nd January 2025\n",
    "\n",
    "            if block is None:\n",
    "                self.logger.error(f'No div with class \"my-6\" found, URL {url} structure has likely been changed\"')\n",
    "                                            \n",
    "            for city in block.find_all('a', class_='text-wpr-link'): # Works as of 22nd Janaury 2025\n",
    "                name = city.text.strip()\n",
    "                if name:\n",
    "                    cities.append(name)\n",
    "\n",
    "            # Check if the cities list is populated\n",
    "            if not cities:\n",
    "                self.logger.warning('No city names found in \"my-6\" block')\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'An error occured while extracting city names: {str(e)}')\n",
    "            raise\n",
    "\n",
    "        return cities\n",
    "\n",
    "    def load_cities(self): # -> List[str]\n",
    "        # Main method to load and process city data\n",
    "        try:\n",
    "            soup = self.fetch_and_parse(self.base_url)\n",
    "            cities = self.extract_cities(soup)\n",
    "\n",
    "            return cities\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Failed to load cities: {str(e)}')\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d2fa52-676c-4fe8-91b1-b4cd282738a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted 500 cities\n",
      "Tokyo\n",
      "Delhi\n",
      "Shanghai\n",
      "Dhaka\n",
      "Sao Paulo\n",
      "Cairo\n",
      "Mexico City\n",
      "Beijing\n",
      "Mumbai\n",
      "Osaka\n"
     ]
    }
   ],
   "source": [
    "def load_city_data(): # -> List[str]\n",
    "    # Wrapper function to create a class, load city data and return a list of cities\n",
    "    loader = CityLoader()\n",
    "    return loader.load_cities()\n",
    "\n",
    "# Test the loader\n",
    "try:\n",
    "    cities = load_city_data()[:500]\n",
    "    print(f'Successfully extracted {len(cities)} cities')\n",
    "    print('\\n'.join(cities[:10])) # Printing 10 city names for testing\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Error during testing: {str(e)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
